{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPTnB9qTXvwBTYJsoE5c0wX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f28491cebc214cbfaee5d52d68b51666":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15e9b9cb48454a1eb9f66423f157dffe","IPY_MODEL_9b41c9c344524e5383e7fdeb440f0e9a","IPY_MODEL_800702665d8a471dbe66b9d8127dbc3d"],"layout":"IPY_MODEL_59245743105648638fa42aadc09519f5"}},"15e9b9cb48454a1eb9f66423f157dffe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e9ba1fc7ff64c80a6d6e7ecbbbf6e98","placeholder":"​","style":"IPY_MODEL_c167eb057ea64d64aa2e235f1a716aa9","value":"Downloading: 100%"}},"9b41c9c344524e5383e7fdeb440f0e9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0a87e242e1c4703aff82e4415471de1","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_963f8ee5f00240e782ec6033f371d3db","value":288}},"800702665d8a471dbe66b9d8127dbc3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ddc2e2320b54382bac5e0644b8d0138","placeholder":"​","style":"IPY_MODEL_0fd0cbe6daa24f4cb4cc7dfaf9614ab9","value":" 288/288 [00:00&lt;00:00, 6.29kB/s]"}},"59245743105648638fa42aadc09519f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e9ba1fc7ff64c80a6d6e7ecbbbf6e98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c167eb057ea64d64aa2e235f1a716aa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0a87e242e1c4703aff82e4415471de1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"963f8ee5f00240e782ec6033f371d3db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ddc2e2320b54382bac5e0644b8d0138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fd0cbe6daa24f4cb4cc7dfaf9614ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f767e9c614864f9198589dc4a28ade64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b52e589513b244a7bc4e2d9a1b111509","IPY_MODEL_9fff0c28e79f45f2ba4351a23801e5e8","IPY_MODEL_a4c27c34fedb4c9ebb6688bd0b0523c4"],"layout":"IPY_MODEL_b5b74454f0d4444c98b3ab7583cf8479"}},"b52e589513b244a7bc4e2d9a1b111509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d76a73f6fab4a10983c8e02833452a4","placeholder":"​","style":"IPY_MODEL_0f14cbfa71c54e73b4d64e86d7954816","value":"Downloading: 100%"}},"9fff0c28e79f45f2ba4351a23801e5e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bcef78a56f74c6187748cff0bc52c1e","max":504,"min":0,"orientation":"horizontal","style":"IPY_MODEL_453113c5842a44d4ab64c8d7a5f76026","value":504}},"a4c27c34fedb4c9ebb6688bd0b0523c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d747e642072f4ee5b7fb38fc369ab285","placeholder":"​","style":"IPY_MODEL_caa7eef006d74a7fb9d69dd91943adca","value":" 504/504 [00:00&lt;00:00, 13.7kB/s]"}},"b5b74454f0d4444c98b3ab7583cf8479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d76a73f6fab4a10983c8e02833452a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f14cbfa71c54e73b4d64e86d7954816":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bcef78a56f74c6187748cff0bc52c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"453113c5842a44d4ab64c8d7a5f76026":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d747e642072f4ee5b7fb38fc369ab285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa7eef006d74a7fb9d69dd91943adca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8eccc80d87dd47cb910e4345ba685209":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d118bc07b3f94091959d33478c1e8e6b","IPY_MODEL_c8c2980b2d2a4e5b88087114e670b7bb","IPY_MODEL_61c0590b933e47778afcb654740c84b9"],"layout":"IPY_MODEL_74ec70e48eac4b77b979ba893a903522"}},"d118bc07b3f94091959d33478c1e8e6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa06ba5ee701475bae8dd267cc216a36","placeholder":"​","style":"IPY_MODEL_511100b019034d60a09bfd4b1312bada","value":"Downloading: 100%"}},"c8c2980b2d2a4e5b88087114e670b7bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bde6711511d2494cac91d7921d6a0d66","max":396417,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59aebcdc9c5b404cb44213f60ecb2430","value":396417}},"61c0590b933e47778afcb654740c84b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ab44e5c18224e698652c192e749a109","placeholder":"​","style":"IPY_MODEL_d680736e122b49dfa8112bed5c5480cc","value":" 396k/396k [00:00&lt;00:00, 394kB/s]"}},"74ec70e48eac4b77b979ba893a903522":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa06ba5ee701475bae8dd267cc216a36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"511100b019034d60a09bfd4b1312bada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bde6711511d2494cac91d7921d6a0d66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59aebcdc9c5b404cb44213f60ecb2430":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ab44e5c18224e698652c192e749a109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d680736e122b49dfa8112bed5c5480cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"564ab2b4cfaa482995d7794ac62da075":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3e207d89f7c403b9d4be905bb8c4e20","IPY_MODEL_1ad726432f8740eabfebda2c9b2fc877","IPY_MODEL_87a0a05ba5cb46b3acd4b34615d67c89"],"layout":"IPY_MODEL_25e608bafd274431b9cdf0ce2aec4c75"}},"c3e207d89f7c403b9d4be905bb8c4e20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abe178aa791447a59879dff78e760fbc","placeholder":"​","style":"IPY_MODEL_379b3127fcbe46bcae18bfad55c76380","value":"Downloading: 100%"}},"1ad726432f8740eabfebda2c9b2fc877":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08bccca062c946ed98a29beeee8d97a7","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_808f7af6d7b74eb8bae2c5bf56f8ec91","value":124}},"87a0a05ba5cb46b3acd4b34615d67c89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ae6e27ea3a242e1a5c35448aa102ef6","placeholder":"​","style":"IPY_MODEL_5ea42dd7bdd442b19562eb8d29121160","value":" 124/124 [00:00&lt;00:00, 3.49kB/s]"}},"25e608bafd274431b9cdf0ce2aec4c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abe178aa791447a59879dff78e760fbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"379b3127fcbe46bcae18bfad55c76380":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08bccca062c946ed98a29beeee8d97a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"808f7af6d7b74eb8bae2c5bf56f8ec91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ae6e27ea3a242e1a5c35448aa102ef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ea42dd7bdd442b19562eb8d29121160":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5a4310a0ec34f0db309a8f8c4c80e67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0be8ee44cc804711a13c36673db3cc57","IPY_MODEL_adefe20026144b1d841356c3e023b7ff","IPY_MODEL_89e772be53ec4a9bb0daf4e3acab10ae"],"layout":"IPY_MODEL_67e26ba0760e4e24962d525c57da6979"}},"0be8ee44cc804711a13c36673db3cc57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53b794802fdf4c109814ccdbc4c7d2e7","placeholder":"​","style":"IPY_MODEL_eb4c519e18884ac0ae49dd371b3b39ca","value":"Downloading: 100%"}},"adefe20026144b1d841356c3e023b7ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8727e494c711467b8a1f4c72e6f1e92f","max":498271049,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90603281eb354466a42c3be002b055d8","value":498271049}},"89e772be53ec4a9bb0daf4e3acab10ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e7c64cf76c441f6ae0d5c7e620c0673","placeholder":"​","style":"IPY_MODEL_e8f3689151fa491191b437fbfc8dd01e","value":" 498M/498M [00:26&lt;00:00, 19.0MB/s]"}},"67e26ba0760e4e24962d525c57da6979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53b794802fdf4c109814ccdbc4c7d2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4c519e18884ac0ae49dd371b3b39ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8727e494c711467b8a1f4c72e6f1e92f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90603281eb354466a42c3be002b055d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e7c64cf76c441f6ae0d5c7e620c0673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8f3689151fa491191b437fbfc8dd01e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSHB1kjMUtV0","executionInfo":{"status":"ok","timestamp":1663651136923,"user_tz":-540,"elapsed":11143,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"bfae9c5a-758d-4915-9dd5-56f1275a1731"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 2.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 37.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["#! git clone https://github.com/ZIZUN/korean-malicious-comments-dataset.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9gBUaJmVZWE","executionInfo":{"status":"ok","timestamp":1663651225675,"user_tz":-540,"elapsed":1327,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"65182915-ee7c-4d04-f070-3307fed0e2ae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'korean-malicious-comments-dataset'...\n","remote: Enumerating objects: 30, done.\u001b[K\n","remote: Counting objects: 100% (30/30), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 30 (delta 15), reused 15 (delta 5), pack-reused 0\u001b[K\n","Unpacking objects: 100% (30/30), done.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from transformers import AutoTokenizer,AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(\"device:\",device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndBnH3ExVxYE","executionInfo":{"status":"ok","timestamp":1663651352307,"user_tz":-540,"elapsed":5148,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"7803f2f1-edd8-4c8e-db13-234f3c4c58f8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cuda:0\n"]}]},{"cell_type":"markdown","source":["데이터셋 제작\n"],"metadata":{"id":"XZ1Z_L0EWRKT"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/Dataset.csv\",sep=\"\\t\")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"rBZyaDwKWPQU","executionInfo":{"status":"ok","timestamp":1663651398797,"user_tz":-540,"elapsed":8,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"5b355102-d1ac-4c0f-e646-c11efde56119"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             content  lable\n","0  이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...    0.0\n","1                    씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ    0.0\n","2                                           짱깨 꺼라ㅡ패쓰    0.0\n","3  그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...    1.0\n","4  아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...    1.0"],"text/html":["\n","  <div id=\"df-f602db82-139a-4066-9f16-711a78247831\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>lable</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>짱깨 꺼라ㅡ패쓰</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f602db82-139a-4066-9f16-711a78247831')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f602db82-139a-4066-9f16-711a78247831 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f602db82-139a-4066-9f16-711a78247831');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrng8N8QWb3t","executionInfo":{"status":"ok","timestamp":1663651411086,"user_tz":-540,"elapsed":5,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"fed5c5db-9347-40c2-bd42-ea6bf9bf1e59"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   content  10000 non-null  object \n"," 1   lable    9975 non-null   float64\n","dtypes: float64(1), object(1)\n","memory usage: 156.4+ KB\n"]}]},{"cell_type":"code","source":["df.isna().sum()  # 25개 결측값 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-lEAcm9We_5","executionInfo":{"status":"ok","timestamp":1663651492990,"user_tz":-540,"elapsed":2,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"f91090a4-266c-40e5-ea51-346c9fa604d4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["content     0\n","lable      25\n","dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbjw8ixQWoOp","executionInfo":{"status":"ok","timestamp":1663651515119,"user_tz":-540,"elapsed":596,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"262b5c1c-c367-4408-d188-d0edec201b31"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   content  10000 non-null  object \n"," 1   lable    9975 non-null   float64\n","dtypes: float64(1), object(1)\n","memory usage: 156.4+ KB\n"]}]},{"cell_type":"markdown","source":["전처리"],"metadata":{"id":"VXGzthhyW6aA"}},{"cell_type":"code","source":["null_idx = df[df.lable.isnull()].index\n","df.loc[null_idx, \"content\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8g-_qh6W4H3","executionInfo":{"status":"ok","timestamp":1663651565153,"user_tz":-540,"elapsed":5,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"b4c675cb-3437-4539-a176-faa66beb7953"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1602    응애 응애 엄마 저 맘에 안들죠? ........아들 ?? \" 너 내가 우스워 보이...\n","1654           토니스타크 평소 \"아이엠그루트\"라는 유행어를 부러워했다는게 학계의 정설\\t1\n","1992    \"13일 현대차에 따르면 올 들어 국내 소비자들의 수입차 구매의향률이 3년 만에 하...\n","2920                 에이프릴이 한마디 합니다 \"예쁜게 죄\" 구하라님 \"무기징역\"\\t1\n","3720          답글 글씨체를 봐라 저게 애새끼가 쓴거냐?\"빨갱이새끼가 쓴거지 ㅁㅈㅎㅉㅉ\\t0\n","3807    알겠다이기ㅋㅋ 딱 채찍쳐맞는거 좋아하는 한국식 마인드네. 노예마인드. 조금만 성공한...\n","3908           이래서 스스로 걸리거든 \"죄인들이\"~ㅎㅎㅎ 재미보고 털리고 그치~~~?\\t0\n","4241    아버지는 내재된 악마들을 다룰 정신적 힘을 가지고 있지 않았다.\" 이 말한마디가 사...\n","4283    댓글 중 \"선동 당해서 촞불든 개돼지 홍어들도 단죄를 받아야 할 공범자들이다\"에10...\n","5000    스파이 제안받고 살해 안당하는 법1. 처음에 스파이 제안을 받았을때 \"중국을 위해서...\n","5521    \"국방부 \"까지 ㅡㄱ ㅐ 엿같은 ㅈ ㅣ랄주댕이...좌빨에서 ㅡ인민군대로 ㅡ가려는건가...\n","5866    쌩뚱맞게 60대최반엌 치매라니 그것도 곱게 사는 사모님이- -\" 알콜중독도 아니고 ...\n","6477    페미메퇘지쿵쾅년인 메갈페미들은 니들이 좋아하는 싫어요 ㄱㄱ제발부탁해~~\"일반 여성\"...\n","6538    아니 ㅆㅂ 그런 \"카더라\"가 넘쳐난다고 그거에 대해서 혹시 댓글게이는 뭔가 아는거 ...\n","6771    저 때 투니버스에서 코요태 짧게 인터뷰 했었는데 김종민이 \"노래는 뭐 신지가 다 하...\n","6932               개 족 가튼 국방부의 \"휴기연장콜센터\"발족을 축하한다 ㅆ ㅂ..\\t0\n","7199    민족적 자존심과 애국심을 갖고 국산품 이용합시다 . . . \"겸손\"한 마음으로 재산...\n","7252    아나운서는 목표가 아니었지ㅋㅋ재벌하고 결혼하자마자 바로 은퇴하네ㅋㅋ무슨 인터뷰한 거...\n","7270    결국 준영과 다솜은 바람을 피게되고 무인도로 떠난다에 한표 ㅋㅋㅋ 자연인이 되어 \"...\n","7480    지금 연락하는 여자랑 폰섹 엄청 많이했는데만나서 호텔 들어가서침대에 서로 마주보고 ...\n","7499    몽골한테 \"최근에\" 250년간 지배당하고 집단강간을 당했는데 동양피가 하나도 안섞였...\n","7887    뭐 선천적으로 여성스럽거나 여자역할을 하고 싶어하는 동성애자들 그럴 수 있다고는 생...\n","9666         ㄹㅇ 시발 그냥 \"다른 진로 생각해 보세요\"라고만 했어도 욕 안처 먹었지.\\t0\n","9698                              간만에 이단어가 떠오르는군 \"이뭐병\"\\t0\n","9875    노라조 \"형\"이란 노래로 힘들 때 위로를 받곤 했습니다. 앞으로도 노라조라는 이름으...\n","Name: content, dtype: object"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# label은 content 가장 끝 문자열로 설정\n","df.loc[null_idx, \"lable\"] = df.loc[null_idx, \"content\"].apply(lambda x: x[-1])\n","\n","# content \"\\t\" 앞부분까지 문자열로 설정\n","df.loc[null_idx, \"content\"] = df.loc[null_idx, \"content\"].apply(lambda x: x[-2])"],"metadata":{"id":"G4zHdAQRXEki","executionInfo":{"status":"ok","timestamp":1663651680103,"user_tz":-540,"elapsed":414,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df = df.astype({\"lable\":\"int\"}) # 학습 위해 int로 변환\n","df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qV2YRdVGXdNN","executionInfo":{"status":"ok","timestamp":1663651717931,"user_tz":-540,"elapsed":3,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"cb62c259-9f6a-40df-e896-975cda17c02c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   content  10000 non-null  object\n"," 1   lable    10000 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 156.4+ KB\n"]}]},{"cell_type":"markdown","source":["데이터셋 나누기"],"metadata":{"id":"lPN3Q5T_XwmN"}},{"cell_type":"code","source":["train_data = df.sample(frac=0.8, random_state=42)\n","test_data = df.drop(train_data.index)"],"metadata":{"id":"Ft34o3sKXmU3","executionInfo":{"status":"ok","timestamp":1663651852527,"user_tz":-540,"elapsed":416,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 갯수 확인\n","print('중복 제거 전 train: {}.',format(len(train_data)))\n","print('중복 제거 전 test: {}.',format(len(test_data)))\n","\n","# 중복 제거\n","train_data.drop_duplicates(subset=[\"content\"],inplace=True)\n","test_data.drop_duplicates(subset=[\"content\"],inplace=True)\n","\n","\n","# 데이터셋 갯수 확인\n","print('중복 제거 후 train: {}.',format(len(train_data)))\n","print('중복 제거 후 test: {}.',format(len(test_data)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfhSg7Z4YH18","executionInfo":{"status":"ok","timestamp":1663651971588,"user_tz":-540,"elapsed":5,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"e8ccaad8-634d-4904-ffd0-6303895767a1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["중복 제거 전 train: {}. 8000\n","중복 제거 전 test: {}. 2000\n","중복 제거 후 train: {}. 7972\n","중복 제거 후 test: {}. 1997\n"]}]},{"cell_type":"markdown","source":["토크나이징"],"metadata":{"id":"SVcd4PbPYpSo"}},{"cell_type":"code","source":["MODEL_NAME = \"beomi/KcELECTRA-base\" # hugging face 에 등록된 모델\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["f28491cebc214cbfaee5d52d68b51666","15e9b9cb48454a1eb9f66423f157dffe","9b41c9c344524e5383e7fdeb440f0e9a","800702665d8a471dbe66b9d8127dbc3d","59245743105648638fa42aadc09519f5","7e9ba1fc7ff64c80a6d6e7ecbbbf6e98","c167eb057ea64d64aa2e235f1a716aa9","f0a87e242e1c4703aff82e4415471de1","963f8ee5f00240e782ec6033f371d3db","1ddc2e2320b54382bac5e0644b8d0138","0fd0cbe6daa24f4cb4cc7dfaf9614ab9","f767e9c614864f9198589dc4a28ade64","b52e589513b244a7bc4e2d9a1b111509","9fff0c28e79f45f2ba4351a23801e5e8","a4c27c34fedb4c9ebb6688bd0b0523c4","b5b74454f0d4444c98b3ab7583cf8479","4d76a73f6fab4a10983c8e02833452a4","0f14cbfa71c54e73b4d64e86d7954816","6bcef78a56f74c6187748cff0bc52c1e","453113c5842a44d4ab64c8d7a5f76026","d747e642072f4ee5b7fb38fc369ab285","caa7eef006d74a7fb9d69dd91943adca","8eccc80d87dd47cb910e4345ba685209","d118bc07b3f94091959d33478c1e8e6b","c8c2980b2d2a4e5b88087114e670b7bb","61c0590b933e47778afcb654740c84b9","74ec70e48eac4b77b979ba893a903522","fa06ba5ee701475bae8dd267cc216a36","511100b019034d60a09bfd4b1312bada","bde6711511d2494cac91d7921d6a0d66","59aebcdc9c5b404cb44213f60ecb2430","7ab44e5c18224e698652c192e749a109","d680736e122b49dfa8112bed5c5480cc","564ab2b4cfaa482995d7794ac62da075","c3e207d89f7c403b9d4be905bb8c4e20","1ad726432f8740eabfebda2c9b2fc877","87a0a05ba5cb46b3acd4b34615d67c89","25e608bafd274431b9cdf0ce2aec4c75","abe178aa791447a59879dff78e760fbc","379b3127fcbe46bcae18bfad55c76380","08bccca062c946ed98a29beeee8d97a7","808f7af6d7b74eb8bae2c5bf56f8ec91","0ae6e27ea3a242e1a5c35448aa102ef6","5ea42dd7bdd442b19562eb8d29121160"]},"id":"ZUenumWpYnwE","executionInfo":{"status":"ok","timestamp":1663652109568,"user_tz":-540,"elapsed":9437,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"96e1080c-d01a-4886-a58a-33f6dc5de456"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/288 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f28491cebc214cbfaee5d52d68b51666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/504 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f767e9c614864f9198589dc4a28ade64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/396k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eccc80d87dd47cb910e4345ba685209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564ab2b4cfaa482995d7794ac62da075"}},"metadata":{}}]},{"cell_type":"code","source":["#학습 데이터 토크나이징\n","tokenized_train_sentences = tokenizer(\n","    list(train_data[\"content\"]),\n","    return_tensors=\"pt\",\n","    max_length=128,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True,)"],"metadata":{"id":"wM4CKSa-ZHKQ","executionInfo":{"status":"ok","timestamp":1663652198994,"user_tz":-540,"elapsed":555,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["print(tokenized_train_sentences[0])\n","print(tokenized_train_sentences[0].tokens)\n","print(tokenized_train_sentences[0].ids)\n","print(tokenized_train_sentences[0].attention_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXAmrRaeZY9a","executionInfo":{"status":"ok","timestamp":1663652250968,"user_tz":-540,"elapsed":454,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"e28f01bc-545d-4d36-9b22-7d692acbc1f1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '국방부', '~', '~', '전화로', '휴가', '##연장', '##을', '한', '병사', '##들', '몇이나', '되는지', '공개해라', '~', '어느', '훌륭한', '집안', '##의', '자제', '##분들', '##인지도', '같이', '공개해라', '~', '~', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 15556, 96, 96, 22864, 10648, 17723, 4053, 3777, 28165, 4134, 20537, 14071, 16341, 96, 8460, 13624, 9747, 4041, 12954, 9160, 14777, 8387, 16341, 96, 96, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["# 테스트 데이터 토크나이징\n","tokenized_test_sentences = tokenizer(\n","    list(train_data[\"content\"]),\n","    return_tensors=\"pt\",\n","    max_length=128,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True,)"],"metadata":{"id":"4HVJL-1zZr2t","executionInfo":{"status":"ok","timestamp":1663652340826,"user_tz":-540,"elapsed":625,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(tokenized_test_sentences[0])\n","print(tokenized_test_sentences[0].tokens)\n","print(tokenized_test_sentences[0].ids)\n","print(tokenized_test_sentences[0].attention_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtdabZZoZ2QU","executionInfo":{"status":"ok","timestamp":1663652342334,"user_tz":-540,"elapsed":5,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"df7c7f0f-e310-4766-fcb7-5dacad78b6eb"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '국방부', '~', '~', '전화로', '휴가', '##연장', '##을', '한', '병사', '##들', '몇이나', '되는지', '공개해라', '~', '어느', '훌륭한', '집안', '##의', '자제', '##분들', '##인지도', '같이', '공개해라', '~', '~', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 15556, 96, 96, 22864, 10648, 17723, 4053, 3777, 28165, 4134, 20537, 14071, 16341, 96, 8460, 13624, 9747, 4041, 12954, 9160, 14777, 8387, 16341, 96, 96, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["class CurseDataset(torch.utils.data.Dataset):\n","  def __init__(self, encodings, labels):\n","    self.encodings = encodings\n","    self.labels = labels\n","\n","  def __getitem__(self, idx):\n","    item = {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n","    item[\"labels\"] = torch.tensor(self.labels[idx])\n","    return item\n","\n","  def __len__(self): \n","    return len(self.labels)                       "],"metadata":{"id":"FbHoQptMahnO","executionInfo":{"status":"ok","timestamp":1663652726242,"user_tz":-540,"elapsed":5,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["train_label = train_data[\"lable\"].values\n","test_label = test_data[\"lable\"].values\n","\n","train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n","test_dataset = CurseDataset(tokenized_test_sentences, test_label)"],"metadata":{"id":"9zdDgVvEZ8G9","executionInfo":{"status":"ok","timestamp":1663652729076,"user_tz":-540,"elapsed":2,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["학습"],"metadata":{"id":"K_j-n2Tsbh9S"}},{"cell_type":"code","source":["# 모델 불러오기\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c5a4310a0ec34f0db309a8f8c4c80e67","0be8ee44cc804711a13c36673db3cc57","adefe20026144b1d841356c3e023b7ff","89e772be53ec4a9bb0daf4e3acab10ae","67e26ba0760e4e24962d525c57da6979","53b794802fdf4c109814ccdbc4c7d2e7","eb4c519e18884ac0ae49dd371b3b39ca","8727e494c711467b8a1f4c72e6f1e92f","90603281eb354466a42c3be002b055d8","4e7c64cf76c441f6ae0d5c7e620c0673","e8f3689151fa491191b437fbfc8dd01e"]},"id":"hyNFgkp_aVs0","executionInfo":{"status":"ok","timestamp":1663652814755,"user_tz":-540,"elapsed":39051,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"45a8ea46-0a87-467f-9007-88930fcde5cc"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/498M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a4310a0ec34f0db309a8f8c4c80e67"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["학습 파라미터 설정"],"metadata":{"id":"6DRPyXKdbuQ9"}},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./',\n","    num_train_epochs=10,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=64,\n","    logging_dir='./loss',\n","    logging_steps=500,\n","    save_total_limit=2,\n",")"],"metadata":{"id":"hvIr0iTtbsIL","executionInfo":{"status":"ok","timestamp":1663652931358,"user_tz":-540,"elapsed":423,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["학습 평가지표 설정\n"],"metadata":{"id":"5EZGa0PycThF"}},{"cell_type":"code","source":["def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average = 'binary')\n","  acc = accuracy_score(labels,preds)\n","  return{\n","      'accuracy':acc,\n","      'f1':f1,\n","      'precision':precision,\n","      'recall':recall\n","  }"],"metadata":{"id":"nypVuYNwcGpm","executionInfo":{"status":"ok","timestamp":1663653048994,"user_tz":-540,"elapsed":733,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"F9UowQ4ScXJ4","executionInfo":{"status":"ok","timestamp":1663653125393,"user_tz":-540,"elapsed":1109,"user":{"displayName":"avery jane","userId":"16844881950893257975"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pIlDiyMjc_vl","executionInfo":{"status":"ok","timestamp":1663654637498,"user_tz":-540,"elapsed":1505340,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"89166690-7da6-4001-bbe6-7ae8f083dcb2"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 7972\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9970\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9970' max='9970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9970/9970 25:02, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.365100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.326800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.185200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.186800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.079800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.090100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.028800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.046700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.021800</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.034700</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.011600</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.016900</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.011700</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.017300</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.007600</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.005300</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.011100</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.000200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./checkpoint-500\n","Configuration saved in ./checkpoint-500/config.json\n","Model weights saved in ./checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-1000\n","Configuration saved in ./checkpoint-1000/config.json\n","Model weights saved in ./checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-1500\n","Configuration saved in ./checkpoint-1500/config.json\n","Model weights saved in ./checkpoint-1500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-2000\n","Configuration saved in ./checkpoint-2000/config.json\n","Model weights saved in ./checkpoint-2000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-1000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-2500\n","Configuration saved in ./checkpoint-2500/config.json\n","Model weights saved in ./checkpoint-2500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-1500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-3000\n","Configuration saved in ./checkpoint-3000/config.json\n","Model weights saved in ./checkpoint-3000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-2000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-3500\n","Configuration saved in ./checkpoint-3500/config.json\n","Model weights saved in ./checkpoint-3500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-2500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-4000\n","Configuration saved in ./checkpoint-4000/config.json\n","Model weights saved in ./checkpoint-4000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-3000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-4500\n","Configuration saved in ./checkpoint-4500/config.json\n","Model weights saved in ./checkpoint-4500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-3500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-5000\n","Configuration saved in ./checkpoint-5000/config.json\n","Model weights saved in ./checkpoint-5000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-4000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-5500\n","Configuration saved in ./checkpoint-5500/config.json\n","Model weights saved in ./checkpoint-5500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-4500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-6000\n","Configuration saved in ./checkpoint-6000/config.json\n","Model weights saved in ./checkpoint-6000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-5000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-6500\n","Configuration saved in ./checkpoint-6500/config.json\n","Model weights saved in ./checkpoint-6500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-5500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-7000\n","Configuration saved in ./checkpoint-7000/config.json\n","Model weights saved in ./checkpoint-7000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-6000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-7500\n","Configuration saved in ./checkpoint-7500/config.json\n","Model weights saved in ./checkpoint-7500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-6500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-8000\n","Configuration saved in ./checkpoint-8000/config.json\n","Model weights saved in ./checkpoint-8000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-7000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-8500\n","Configuration saved in ./checkpoint-8500/config.json\n","Model weights saved in ./checkpoint-8500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-7500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-9000\n","Configuration saved in ./checkpoint-9000/config.json\n","Model weights saved in ./checkpoint-9000/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-8000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","Saving model checkpoint to ./checkpoint-9500\n","Configuration saved in ./checkpoint-9500/config.json\n","Model weights saved in ./checkpoint-9500/pytorch_model.bin\n","Deleting older checkpoint [checkpoint-8500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=9970, training_loss=0.07328897649823962, metrics={'train_runtime': 1505.4798, 'train_samples_per_second': 52.953, 'train_steps_per_second': 6.622, 'total_flos': 5243803333324800.0, 'train_loss': 0.07328897649823962, 'epoch': 10.0})"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["모델평가"],"metadata":{"id":"M6rAH3vMls_-"}},{"cell_type":"code","source":["trainer.evaluate(eval_dataset=test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"_8mwCtp7dDAx","executionInfo":{"status":"ok","timestamp":1663654799009,"user_tz":-540,"elapsed":7460,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"68c86714-521d-4c75-97f0-a6d69c253438"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1997\n","  Batch size = 64\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 5.253864288330078,\n"," 'eval_accuracy': 0.5037556334501753,\n"," 'eval_f1': 0.5012581781580272,\n"," 'eval_precision': 0.49700598802395207,\n"," 'eval_recall': 0.5055837563451777,\n"," 'eval_runtime': 7.1974,\n"," 'eval_samples_per_second': 277.463,\n"," 'eval_steps_per_second': 4.446,\n"," 'epoch': 10.0}"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["def sentence_predict(sent):\n","  model.eval() # 평가\n","\n","  # 입력문장 토크나이징\n","  tokenized_sent = tokenizer(\n","      sent,\n","      return_tensors=\"pt\",\n","      truncation=True, \n","      add_special_tokens=True, \n","      max_length=128\n","      )\n","\n","  # 모델 위치 gpu이동\n","  tokenized_sent.to(device)\n","\n","  # 예측\n","  with torch.no_grad():\n","    outputs = model(\n","        input_ids=tokenized_sent[\"input_ids\"],\n","        attention_mask=tokenized_sent[\"attention_mask\"],\n","        token_type_ids=tokenized_sent[\"token_type_ids\"],\n","    )\n","\n","  # 결과\n","  logits = outputs[0]   ## 마지막 노드에서 아무런 Activation Function을 거치지 않은 값을 Logit\n","  logits = logits.detach().cpu()\n","  result = logits.argmax(-1)\n","  if result == 0:\n","    result = \">> 악성ㅋ\"\n","  elif result ==1:\n","    result= \">> 정상ㅇ\"\n","  return result\n","  \n","\n","while True:\n","  sentence = input(\"댓글을 입력 해주세요:\")\n","  if sentence == \"0\":\n","      break\n","  print(sentence_predict(sentence))\n","  print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDtv3asOdbJG","executionInfo":{"status":"ok","timestamp":1663655835981,"user_tz":-540,"elapsed":22116,"user":{"displayName":"avery jane","userId":"16844881950893257975"}},"outputId":"babdf0e2-dca5-4b60-fa4b-ad064d90ef8b"},"execution_count":66,"outputs":[{"name":"stdout","output_type":"stream","text":["댓글을 입력 해주세요:이 바보야\n",">> 악성ㅋ\n","\n","\n","댓글을 입력 해주세요:너 너무착해\n",">> 정상ㅇ\n","\n","\n","댓글을 입력 해주세요:이 똥아\n",">> 악성ㅋ\n","\n","\n","댓글을 입력 해주세요:0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YWj0wKySmaTG"},"execution_count":null,"outputs":[]}]}